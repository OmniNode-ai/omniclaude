---
# ONEX Contract v2.0
contract_version: "2.0"
node_type: "orchestrator"
node_name: "DebugLoopOrchestrator"
description: "Coordinate debug intelligence extraction and application workflow across all debug loop nodes"

# Associated Documents (ONEX Linked Documents Pattern)
associated_documents:
  architecture:
    - path: "docs/analysis/DEBUG_REWARDS_CLARIFICATION_ANALYSIS.md"
      purpose: "System design and component interactions for debug loop"
      relationship: "architecture_design"
    - path: "docs/planning/DEBUG_LOOP_IMPLEMENTATION_PLAN.md"
      purpose: "Phase-by-phase implementation details"
      section: "Part 1: Debug Intelligence Core"
      relationship: "implementation_guide"
    - path: "CLAUDE.md"
      section: "Agent Observability & Traceability"
      purpose: "Debug loop architecture and observability patterns"
      relationship: "architecture_overview"
    - path: "docs/observability/AGENT_TRACEABILITY.md"
      purpose: "Three-layer traceability: routing → manifest → execution"
      relationship: "observability_guide"

  implementation:
    - path: "omniclaude/debug_loop/node_*.py"
      purpose: "Debug loop node implementation files"
      relationship: "node_implementations"
    - path: "migrations/001_debug_loop_core_schema.sql"
      purpose: "Database schema for debug loop"
      relationship: "database_schema"
    - path: "contracts/debug_loop/debug_stf_extractor_compute.yaml"
      purpose: "STF extraction from successful executions"
      relationship: "orchestrates"
    - path: "contracts/debug_loop/stf_quality_compute.yaml"
      purpose: "Quality scoring for extracted STFs"
      relationship: "orchestrates"
    - path: "contracts/debug_loop/stf_hash_compute.yaml"
      purpose: "Hash generation for STF deduplication"
      relationship: "orchestrates"
    - path: "contracts/debug_loop/debug_stf_storage_effect.yaml"
      purpose: "STF persistence to PostgreSQL"
      relationship: "orchestrates"
    - path: "contracts/debug_loop/stf_matcher_compute.yaml"
      purpose: "Similarity matching for STF recommendations"
      relationship: "orchestrates"
    - path: "contracts/debug_loop/cost_tracker_compute.yaml"
      purpose: "LLM cost calculation and tracking"
      relationship: "orchestrates"
    - path: "contracts/debug_loop/error_pattern_extractor_compute.yaml"
      purpose: "Error pattern extraction and normalization"
      relationship: "orchestrates"
    - path: "contracts/debug_loop/error_success_mapping_reducer.yaml"
      purpose: "Error-to-success mapping aggregation"
      relationship: "orchestrates"
    - path: "contracts/debug_loop/golden_state_manager_reducer.yaml"
      purpose: "Golden state nomination and approval"
      relationship: "orchestrates"

  configuration:
    - path: "config/debug_loop.yaml"
      purpose: "Runtime configuration (to be created)"
      relationship: "runtime_config"
    - path: "agents/definitions/polymorphic-agent.yaml"
      purpose: "Agent configuration for debug loop orchestration"
      relationship: "agent_config"
    - path: "config/settings.py"
      purpose: "Type-safe configuration for database and feature flags"
      relationship: "system_config"

  testing:
    - path: "omniclaude/debug_loop/test_*.py"
      purpose: "Unit and integration tests"
      relationship: "test_suite"

# omnibase_core Models Used
models:
  from_omnibase_core:
    - "omnibase_core.errors.model_onex_error.ModelOnexError"
    - "omnibase_core.errors.error_codes.EnumCoreErrorCode"
    - "omnibase_core.models.common.model_error_context.ModelErrorContext"

# Input Contract
input:
  execution_id:
    type: "string"
    format: "uuid"
    required: true
    description: "Unique execution identifier"

  correlation_id:
    type: "string"
    format: "uuid"
    required: true
    description: "Correlation ID for tracing across systems"

  user_request:
    type: "string"
    required: true
    description: "Original user request/prompt"

  execution_status:
    type: "enum"
    values: ["success", "error", "partial", "cancelled"]
    required: true

  execution_data:
    type: "object"
    required: true
    properties:
      tools_used:
        type: "array"
        items:
          type: "string"
        description: "List of tools used (Read, Edit, Bash, etc)"
      code_written:
        type: "string"
        required: false
        description: "Code that was written during execution"
      files_modified:
        type: "array"
        items:
          type: "string"
        required: false
      model_used:
        type: "string"
        required: true
      tokens_input:
        type: "integer"
        required: false
      tokens_output:
        type: "integer"
        required: false
      quality_score:
        type: "float"
        min: 0.0
        max: 1.0
        required: false
      duration_ms:
        type: "integer"
        required: false
      error_type:
        type: "string"
        required_for_status: ["error"]
      error_message:
        type: "string"
        required_for_status: ["error"]

  options:
    type: "object"
    required: false
    properties:
      extract_stf:
        type: "boolean"
        default: true
        description: "Whether to extract STF from execution"
      calculate_quality:
        type: "boolean"
        default: true
      match_similar:
        type: "boolean"
        default: true
      create_error_mapping:
        type: "boolean"
        default: true
      nominate_golden_state:
        type: "boolean"
        default: true
      min_quality_for_golden:
        type: "float"
        default: 0.9
        description: "Minimum quality score to nominate as golden state"

# Output Contract
output:
  workflow_status:
    type: "enum"
    values: ["completed", "partial", "failed"]
    required: true

  steps_completed:
    type: "array"
    required: true
    items:
      type: "object"
      properties:
        step_name:
          type: "string"
        node_name:
          type: "string"
        status:
          type: "string"  # success, error, skipped
        duration_ms:
          type: "integer"
        error_message:
          type: "string"

  # STF Extraction Results
  stf_extracted:
    type: "boolean"
    required: true

  stf_id:
    type: "string"
    format: "uuid"
    required: false
    description: "ID of extracted STF (if successful)"

  stf_quality_score:
    type: "float"
    required: false

  # Similarity Matching Results
  similar_stfs_found:
    type: "integer"
    required: true

  similar_stfs:
    type: "array"
    items:
      type: "object"
      properties:
        stf_id:
          type: "string"
        stf_name:
          type: "string"
        similarity_score:
          type: "float"
        quality_score:
          type: "float"
    required: false

  # Error Mapping Results
  error_mapping_created:
    type: "boolean"
    required: true

  error_mapping_id:
    type: "string"
    format: "uuid"
    required: false

  # Golden State Results
  golden_state_nominated:
    type: "boolean"
    required: true

  golden_state_id:
    type: "string"
    format: "uuid"
    required: false

  # Intelligence Summary
  intelligence_summary:
    type: "object"
    required: true
    properties:
      stfs_matched:
        type: "integer"
      confidence_score:
        type: "float"
        min: 0.0
        max: 1.0
      recommendations:
        type: "array"
        items:
          type: "string"
        description: "Actionable recommendations based on patterns"
      estimated_cost_usd:
        type: "float"
        description: "Estimated cost of this execution"

  # Workflow Metadata
  total_duration_ms:
    type: "integer"
    required: true

  timestamp:
    type: "datetime"
    required: true

# Workflow Steps (executed in order)
workflow_steps:
  - step: "extract_stf"
    node: "NodeDebugSTFExtractorCompute"
    input_from: "execution_data.code_written"
    condition: "execution_status == 'success' AND code_written IS NOT NULL"
    on_error: "continue"  # Non-critical, continue workflow

  - step: "calculate_quality"
    node: "NodeSTFQualityCompute"
    input_from: "extract_stf.stf_code"
    condition: "extract_stf.success == true"
    on_error: "continue"

  - step: "generate_hash"
    node: "NodeSTFHashCompute"
    input_from: "extract_stf.stf_code"
    condition: "extract_stf.success == true"
    on_error: "fail"  # Critical for deduplication

  - step: "store_stf"
    node: "NodeDebugSTFStorageEffect"
    input_from: "extract_stf.stf_code + calculate_quality.quality_score + generate_hash.stf_hash"
    condition: "extract_stf.success == true AND generate_hash.success == true"
    on_error: "continue"  # Log error but continue

  - step: "match_similar"
    node: "NodeSTFMatcherCompute"
    input_from: "user_request"
    condition: "always"
    on_error: "continue"

  - step: "calculate_cost"
    node: "NodeCostTrackerCompute"
    input_from: "execution_data.tokens_input + execution_data.tokens_output + execution_data.model_used"
    condition: "execution_data.tokens_input IS NOT NULL"
    on_error: "continue"

  - step: "extract_error_pattern"
    node: "NodeErrorPatternExtractorCompute"
    input_from: "execution_data.error_message"
    condition: "execution_status == 'error'"
    on_error: "continue"

  - step: "create_error_mapping"
    node: "NodeErrorSuccessMappingReducer"
    input_from: "extract_error_pattern.error_pattern + stf_id"
    condition: "execution_status == 'error' AND extract_error_pattern.success == true"
    on_error: "continue"

  - step: "nominate_golden_state"
    node: "NodeGoldenStateManagerReducer"
    input_from: "execution_data + stf_id + calculate_quality.quality_score"
    condition: "execution_status == 'success' AND calculate_quality.quality_score >= options.min_quality_for_golden"
    on_error: "continue"

# Service Registry Pattern - Capability-Based Dependencies
# Orchestrator depends on service capabilities, not concrete node implementations
# Enables runtime flexibility, easier testing, and loose coupling
# Service resolution: At runtime, the orchestrator discovers nodes that provide
# the required capabilities by querying the service registry. Nodes register
# themselves with capabilities they provide. This allows swapping implementations
# without changing the orchestrator contract.
dependencies:
  services:
    - capability: "stf_extraction"
      contract_type: "compute"
      description: "Extract structured transform functions from code"
      required: true
      timeout_ms: 2000

    - capability: "stf_storage"
      contract_type: "effect"
      description: "Persist and retrieve STFs from database"
      required: true
      timeout_ms: 1000

    - capability: "stf_quality_scoring"
      contract_type: "compute"
      description: "Calculate quality metrics for STFs"
      required: false
      timeout_ms: 1000

    - capability: "stf_hashing"
      contract_type: "compute"
      description: "Generate content hash for deduplication"
      required: true
      timeout_ms: 500
      critical: true  # Must succeed for deduplication

    - capability: "error_pattern_extraction"
      contract_type: "compute"
      description: "Identify and categorize error patterns"
      required: false
      timeout_ms: 1000

    - capability: "error_success_mapping"
      contract_type: "reducer"
      description: "Correlate errors with successful resolutions"
      required: false
      timeout_ms: 1500

    - capability: "golden_state_management"
      contract_type: "reducer"
      description: "Manage workflow state machine transitions"
      required: false
      timeout_ms: 1000

    - capability: "model_price_lookup"
      contract_type: "effect"
      description: "Query LLM provider pricing information"
      required: true
      timeout_ms: 500

    - capability: "cost_calculation"
      contract_type: "compute"
      description: "Calculate execution costs based on model usage"
      required: false
      timeout_ms: 500

  # Service Resolution Configuration
  resolution:
    method: "capability_matching"
    registry_path: "~/.claude/agent-definitions/"
    fallback_strategy: "graceful_degradation"
    cache_ttl_seconds: 300

  # Runtime Service Discovery
  # 1. Orchestrator requests capability (e.g., "stf_extraction")
  # 2. Service registry queries all registered nodes
  # 3. Nodes with matching capability + contract_type are returned
  # 4. Orchestrator selects first available or uses load balancing
  # 5. If no match found: use fallback_strategy (fail or degrade gracefully)

  protocols:
    - "IDatabaseProtocol"  # For direct DB access if needed

# Error Handling
error_handling:
  strategy: "graceful_degradation"
  description: "Continue workflow even if non-critical steps fail"

  critical_steps:
    - "generate_hash"  # Must succeed for deduplication

  non_critical_steps:
    - "extract_stf"
    - "calculate_quality"
    - "store_stf"
    - "match_similar"
    - "calculate_cost"
    - "extract_error_pattern"
    - "create_error_mapping"
    - "nominate_golden_state"

# Performance Targets
performance:
  target_latency_ms: 2000
  max_latency_ms: 5000
  target_throughput_rps: 10

# ONEX Compliance
onex_compliance:
  base_class: "omnibase_core.core.infrastructure_service_bases.NodeOrchestratorService"
  method_signature: "async def execute_orchestration(self, contract: ModelContractOrchestrator) -> ModelOrchestratorOutput"
  coordinates_nodes: true
  uses_dependency_injection: true

# Testing Requirements
testing:
  unit_tests:
    - "Test successful execution workflow (all steps)"
    - "Test error execution workflow (error mapping)"
    - "Test partial execution (some steps fail)"
    - "Test golden state nomination (high quality)"
    - "Test golden state skip (low quality)"
    - "Test graceful degradation (non-critical failure)"

  integration_tests:
    - "Test with all mocked nodes"
    - "Test with real node implementations"
    - "Test with mixed success/failure scenarios"

  mocks:
    - "MockDebugSTFExtractorCompute"
    - "MockDebugSTFStorageEffect"
    - "MockSTFQualityCompute"
    - "Mock all 9 debug loop nodes"
