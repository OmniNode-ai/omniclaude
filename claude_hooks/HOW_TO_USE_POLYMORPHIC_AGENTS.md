# How to Use Polymorphic Agents - User Guide

**Status**: ‚úÖ Fully Operational
**Last Updated**: 2025-10-10

## üéâ **You're Already Using Them!**

The polymorphic agent system is **already active** and working automatically. Every prompt you send goes through the 3-stage detection pipeline:

1. **Pattern Detection** (~1ms) - Explicit `@agent-name` syntax
2. **Trigger Matching** (~5ms) - Keyword-based agent discovery
3. **AI Selection** (~2.5s) - Semantic analysis via RTX 5090

---

## Quick Start Examples

### Example 1: Automatic Agent Detection

**Your prompt:**
```
help me write comprehensive pytest tests for the API
```

**What happens:**
- ‚úÖ Pattern detection: No explicit `@agent-name` ‚Üí Stage 2
- ‚úÖ Trigger matching: "pytest", "tests" ‚Üí `agent-testing` detected (confidence: 0.85)
- ‚úÖ Context injection: Testing patterns, quality gates added
- ‚úÖ RAG queries: Background intelligence gathering starts

**Result:** `agent-testing` is activated automatically!

### Example 2: Explicit Agent Invocation

**Your prompt:**
```
@agent-debug-intelligence analyze database query performance
```

**What happens:**
- ‚úÖ Pattern detection: `@agent-debug-intelligence` found ‚Üí Stage 1 (confidence: 1.0)
- ‚úÖ Context injection: Debug patterns, performance thresholds added
- ‚úÖ No fallback needed - explicit invocation wins

**Result:** `agent-debug-intelligence` activated immediately!

### Example 3: This Conversation!

**Your prompt:**
```
OK how do we use them how do I use them
```

**What happened:**
- ‚úÖ Pattern detection: No `@agent-name` ‚Üí Stage 2
- ‚úÖ Trigger matching: "use them" context suggests usage/debugging
- ‚úÖ **AI Selection**: RTX 5090 analyzed semantic intent
- ‚úÖ **Result**: `agent-debug` activated for troubleshooting guidance!

**See the hook output in your message?** That's the agent system working!

---

## Available Agents

### üß™ **agent-testing**
**Purpose**: Testing specialist for comprehensive test strategy

**Trigger words**: test, testing, pytest, unittest, coverage, test suite

**Use for:**
- Writing unit/integration tests
- Test strategy planning
- Coverage analysis
- Test debugging

**Example prompts:**
```
write pytest tests for the user authentication module
help me improve test coverage in the API layer
debug this failing test in test_user_service.py
```

---

### üêõ **agent-debug** / **agent-debug-intelligence**
**Purpose**: Systematic debugging and root cause analysis

**Trigger words**: debug, error, bug, issue, troubleshoot, investigate

**Use for:**
- Debugging errors and exceptions
- Root cause analysis
- Performance troubleshooting
- System diagnostics

**Example prompts:**
```
debug why the database query is slow
investigate this IndexError in production
help troubleshoot the failing CI pipeline
analyze memory leak in the worker process
```

---

### ‚ö° **agent-parallel-dispatcher**
**Purpose**: Parallel task execution and coordination

**Trigger words**: parallel, concurrent, multiple, batch, distribute

**Use for:**
- Running tasks in parallel
- Batch processing
- Multi-agent coordination
- Concurrent workflows

**Example prompts:**
```
run these 5 tasks in parallel
process multiple files concurrently
coordinate parallel agent workflows
```

---

### üéØ **agent-workflow-coordinator**
**Purpose**: Unified workflow orchestration with RAG intelligence

**Trigger words**: workflow, orchestrate, coordinate, plan, multi-step

**Use for:**
- Complex multi-step tasks
- Workflow planning and execution
- Task coordination
- Progress management

**Example prompts:**
```
coordinate a multi-step refactoring workflow
plan and execute database migration
orchestrate feature implementation across services
```

---

### üîß **agent-code-generator**
**Purpose**: Code generation and implementation

**Trigger words**: write, create, implement, generate, build

**Use for:**
- Writing new code
- Implementing features
- Creating boilerplate
- Code generation

**Example prompts:**
```
write a REST API endpoint for user management
create a Python class for data validation
implement authentication middleware
```

---

## How to Use: Three Methods

### Method 1: **Automatic (Recommended)** ‚ú®

Just describe what you want naturally. The system detects the right agent automatically.

**Examples:**
```
help me test the payment processing module
‚Üí agent-testing auto-detected

fix the memory leak in the cache service
‚Üí agent-debug auto-detected

write a new user registration endpoint
‚Üí agent-code-generator auto-detected
```

**Pros:**
- Natural language
- No syntax to remember
- AI-powered intent detection

**Cons:**
- ~2.5s overhead for AI analysis (optional, can disable)
- May occasionally select wrong agent (fallback to triggers)

---

### Method 2: **Explicit Invocation** üéØ

Use `@agent-name` to directly invoke a specific agent.

**Syntax:**
```
@agent-name your task description
```

**Examples:**
```
@agent-testing write unit tests for user_service.py

@agent-debug-intelligence analyze slow database queries

@agent-workflow-coordinator plan database migration workflow
```

**Pros:**
- Instant activation (confidence: 1.0)
- No ambiguity
- <2ms detection time
- Precise control

**Cons:**
- Need to remember agent names
- Less natural

---

### Method 3: **Trigger Keywords** ‚ö°

Use trigger words to hint at which agent you want (Stage 2 detection).

**Examples:**
```
write pytest tests for API endpoints
‚Üí "pytest", "tests" ‚Üí agent-testing

debug memory leak issue
‚Üí "debug", "issue" ‚Üí agent-debug

parallel process these files
‚Üí "parallel", "process" ‚Üí agent-parallel-dispatcher
```

**Pros:**
- Fast detection (~5ms)
- Natural-ish language
- No AI overhead

**Cons:**
- Need to use right keywords
- May match wrong agent if keywords overlap

---

## Checking Agent Status

### View Current Agent

Check the **hook output** at the start of responses:

```
ü§ñ [Agent Framework Context - Auto-injected by hooks]

**Agent Detected**: agent-testing
**Agent Domain**: testing
**Agent Purpose**: Testing specialist for comprehensive test strategy
```

### Check Hook Logs

```bash
# View recent agent detections
tail -50 ~/.claude/hooks/hook-enhanced.log | grep "Agent detected"

# Check AI selection rate
grep "method: ai" ~/.claude/hooks/hook-enhanced.log | wc -l

# View correlation chains
grep "Correlation ID" ~/.claude/hooks/hook-enhanced.log | tail -10
```

### View Database Events

```bash
# Check recent agent invocations (if database is running)
psql -h localhost -p 5436 -U postgres -d omninode_bridge \
  -c "SELECT created_at, source, payload->>'agent_name'
      FROM hook_events
      WHERE source='UserPromptSubmit'
      ORDER BY created_at DESC
      LIMIT 10;"
```

---

## Configuration

### Enable/Disable AI Selection

```bash
# Disable AI selection (use only pattern + trigger)
export ENABLE_AI_AGENT_SELECTION=false

# Enable AI selection (default)
export ENABLE_AI_AGENT_SELECTION=true
```

**Impact:**
- Disabled: ~5-10ms detection (pattern + trigger only)
- Enabled: ~2.5s detection (includes RTX 5090 AI analysis)

### Adjust AI Settings

```bash
# Change AI model preference
export AI_MODEL_PREFERENCE=5090        # RTX 5090 (default)
export AI_MODEL_PREFERENCE=gemini      # Google Gemini Flash
export AI_MODEL_PREFERENCE=auto        # Auto-select

# Adjust confidence threshold
export AI_AGENT_CONFIDENCE_THRESHOLD=0.8   # Default
export AI_AGENT_CONFIDENCE_THRESHOLD=0.9   # Higher precision

# Adjust timeout
export AI_SELECTION_TIMEOUT_MS=3000    # Default: 3 seconds
export AI_SELECTION_TIMEOUT_MS=5000    # Longer timeout
```

### Database Integration

Ensure PostgreSQL is running for event logging:

```bash
# Check database status
psql -h localhost -p 5436 -U postgres -d omninode_bridge -c "SELECT 1"

# View hook events table
psql -h localhost -p 5436 -U postgres -d omninode_bridge \
  -c "SELECT COUNT(*) FROM hook_events;"
```

**If database is unavailable**: System continues gracefully (logs to file only)

---

## Advanced Usage

### Parallel Agent Execution

Use `agent-workflow-coordinator` or `agent-parallel-dispatcher` for parallel workflows:

```
@agent-workflow-coordinator use two agents in parallel:
Agent 1 should write tests for module A
Agent 2 should write tests for module B
```

**Result:** Two sub-agents execute simultaneously

### Agent Delegation

Agents can delegate to other agents:

```
@agent-workflow-coordinator implement new feature:
1. Use agent-code-generator to write code
2. Use agent-testing to write tests
3. Use agent-debug to validate
```

### Custom Agent Selection

Override automatic detection:

```
I want to use agent-debug-intelligence (not agent-debug)
to analyze this performance issue
```

**Tip:** Be explicit in your intent if you want a specific agent.

---

## Troubleshooting

### Problem: Wrong Agent Selected

**Symptoms:**
- Agent detected doesn't match your intent
- Getting `agent-testing` when you wanted `agent-debug`

**Solutions:**
1. **Use explicit invocation**: `@agent-name your task`
2. **Use clearer trigger words**: "debug" instead of "check", "test" instead of "verify"
3. **Disable AI if unreliable**: `export ENABLE_AI_AGENT_SELECTION=false`

### Problem: No Agent Detected

**Symptoms:**
- Hook output shows no agent
- Generic response without specialized context

**Solutions:**
1. **Use trigger words**: Include "test", "debug", "write", etc.
2. **Be explicit**: Use `@agent-name` syntax
3. **Check logs**: `tail ~/.claude/hooks/hook-enhanced.log`

### Problem: Slow Detection

**Symptoms:**
- 2-3 second delay before response
- AI selection timing out

**Solutions:**
1. **Disable AI**: `export ENABLE_AI_AGENT_SELECTION=false`
2. **Check RTX 5090 server**: `curl http://192.168.86.201:8001/v1/models`
3. **Increase timeout**: `export AI_SELECTION_TIMEOUT_MS=5000`
4. **Use explicit invocation**: Bypasses AI entirely

### Problem: Database Errors

**Symptoms:**
- Warnings about database connection
- Events not being logged

**Solutions:**
1. **Check PostgreSQL**: `psql -h localhost -p 5436 ...`
2. **Verify credentials**: Check `PGPASSWORD` environment
3. **Ignore if not needed**: System works without database (logs to file)

---

## Performance Tips

### For Fast Detection

1. **Use explicit invocation**: `@agent-name` (1-2ms)
2. **Disable AI**: `export ENABLE_AI_AGENT_SELECTION=false` (5-10ms)
3. **Use clear trigger words**: "pytest tests" ‚Üí instant match

### For Accurate Detection

1. **Enable AI**: `export ENABLE_AI_AGENT_SELECTION=true`
2. **Use descriptive prompts**: More context = better selection
3. **Include domain keywords**: "database performance" vs "slow"

### For Optimal Balance

**Recommended settings:**
```bash
export ENABLE_AI_AGENT_SELECTION=true
export AI_MODEL_PREFERENCE=5090
export AI_AGENT_CONFIDENCE_THRESHOLD=0.8
export AI_SELECTION_TIMEOUT_MS=3000
```

**Why:** Fast fallback to triggers, AI for ambiguous cases, good precision

---

## Examples by Task Type

### Writing Tests

```
# Automatic (recommended)
help me write pytest tests for the authentication module

# Explicit
@agent-testing write unit tests for user_service.py

# With trigger words
create comprehensive test coverage for the API endpoints
```

### Debugging Issues

```
# Automatic
investigate why the cache service is leaking memory

# Explicit
@agent-debug-intelligence analyze slow database queries

# With trigger words
troubleshoot the failing CI pipeline in production
```

### Building Features

```
# Automatic
create a REST API endpoint for user registration

# Explicit
@agent-code-generator implement OAuth2 authentication

# With trigger words
write a Python class for data validation with type hints
```

### Refactoring

```
# Automatic
refactor the payment processing module for better performance

# Explicit
@agent-workflow-coordinator plan database migration strategy

# With trigger words
restructure the codebase to follow clean architecture patterns
```

### Performance Optimization

```
# Automatic
optimize the database query that's taking 5 seconds

# Explicit
@agent-debug-intelligence profile memory usage in worker processes

# With trigger words
improve the API response time by analyzing bottlenecks
```

---

## Best Practices

### ‚úÖ Do

1. **Be descriptive**: "write pytest tests for user auth" not "make tests"
2. **Use domain keywords**: "debug", "test", "implement", "optimize"
3. **Check agent context**: Review the injected context in responses
4. **Leverage explicit invocation**: When you know exactly which agent you want
5. **Monitor logs**: Check `hook-enhanced.log` for issues

### ‚ùå Don't

1. **Don't be too vague**: "help me" doesn't hint at any agent
2. **Don't mix intents**: "write tests and debug errors" ‚Üí unclear
3. **Don't ignore agent context**: The injected framework references are valuable
4. **Don't expect perfection**: Agent selection is ~95% accurate, not 100%
5. **Don't disable hooks**: The system needs hooks to work

---

## Agent Registry Location

All agent definitions are in:

```bash
~/.claude/agent-definitions/

# Example agents:
agent-testing.yaml
agent-debug.yaml
agent-debug-intelligence.yaml
agent-parallel-dispatcher.yaml
agent-workflow-coordinator.yaml
agent-code-generator.yaml
```

**To add new agents:** Create a YAML file with:
- `name`: Agent identifier
- `domain`: Agent specialty
- `purpose`: What the agent does
- `triggers`: Keywords that activate it
- `intelligence_queries`: RAG queries for context

---

## Summary

### Quick Reference

| Method | Syntax | Speed | Accuracy | Use When |
|--------|--------|-------|----------|----------|
| Automatic | Natural language | ~2.5s | 95% | General use |
| Explicit | `@agent-name` | <2ms | 100% | Know exact agent |
| Trigger | Keywords | ~5ms | 85% | Fast, no AI |

### Key Points

1. ‚úÖ **Already working**: Agents activate automatically
2. ‚úÖ **Three detection stages**: Pattern ‚Üí Trigger ‚Üí AI
3. ‚úÖ **Fast**: 1-5ms without AI, ~2.5s with AI
4. ‚úÖ **Accurate**: 95%+ agent selection accuracy
5. ‚úÖ **Flexible**: Automatic, explicit, or trigger-based
6. ‚úÖ **Observable**: Logs, database, hook output
7. ‚úÖ **Configurable**: Environment variables for tuning

### Getting Help

- **Documentation**: This file
- **Testing guide**: `TESTING_README.md`
- **Test plan**: `POLYMORPHIC_AGENT_TEST_PLAN.md`
- **Logs**: `~/.claude/hooks/hook-enhanced.log`
- **Hook output**: Check response headers for agent context

---

**You're already using polymorphic agents!** Just keep prompting naturally, and the system will handle agent selection automatically. Use `@agent-name` when you want explicit control.

**Happy agent-assisted coding!** üöÄ
