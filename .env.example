# OmniClaude Environment Configuration
# ==============================================================================
# Copy this file to .env and fill in your actual API keys
# Never commit .env to version control!
#
# Setup Instructions:
# 1. cp .env.example .env
# 2. Edit .env with your actual API keys
# 3. source .env (or use direnv)
# 4. Verify: echo $GEMINI_API_KEY
#
# See SECURITY_KEY_ROTATION.md for detailed setup and rotation procedures
# ==============================================================================

# ------------------------------------------------------------------------------
# Google Gemini API Configuration
# ------------------------------------------------------------------------------
# Used by: Multi-provider support, AI quorum validation
# Get your key: https://console.cloud.google.com/apis/credentials
# Required for: Gemini Pro, Gemini Flash, Gemini 2.5 Flash providers
# Permissions: Enable "Generative Language API"
# Rate Limits: Check Google Cloud Console for your tier
GEMINI_API_KEY=your_gemini_api_key_here

# Google API Key (Pydantic AI Integration)
# Note: This should be the same as GEMINI_API_KEY for Pydantic AI compatibility
GOOGLE_API_KEY=your_gemini_api_key_here

# ------------------------------------------------------------------------------
# Z.ai API Configuration
# ------------------------------------------------------------------------------
# Used by: GLM model support, high-concurrency operations
# Get your key: https://z.ai/dashboard (or appropriate Z.ai portal)
# Required for: Z.ai provider (GLM-4.5-Air, GLM-4.5, GLM-4.6)
# Rate Limits:
#   - GLM-4.5-Air: 5 concurrent requests
#   - GLM-4.5: 20 concurrent requests
#   - GLM-4.6: 10 concurrent requests
ZAI_API_KEY=your_zai_api_key_here

# ------------------------------------------------------------------------------
# PostgreSQL Database Configuration
# ------------------------------------------------------------------------------
# Used by: Claude Code hooks, agent tracking, pattern traceability
# Purpose: Stores hook events, agent detections, tool usage, correlation tracking
# Database: PostgreSQL (omninode_bridge)
#
# REQUIRED: Set these for your environment (no defaults provided)
# Examples:
#   - Local development: POSTGRES_HOST=localhost, POSTGRES_PORT=5436
#   - Remote server: POSTGRES_HOST=192.168.86.200, POSTGRES_PORT=5436
#   - Docker internal: POSTGRES_HOST=omniclaude_postgres, POSTGRES_PORT=5432
#
POSTGRES_HOST=
# Example: POSTGRES_HOST=localhost or POSTGRES_HOST=192.168.86.200

POSTGRES_PORT=
# Example: POSTGRES_PORT=5436

POSTGRES_DB=
# Example: POSTGRES_DB=omninode_bridge

POSTGRES_USER=
# Example: POSTGRES_USER=postgres

POSTGRES_PASSWORD=
# Example: POSTGRES_PASSWORD=your_secure_password_here
# SECURITY WARNING: Change default in production!

# Legacy alias for backward compatibility
DB_PASSWORD=
# Example: DB_PASSWORD=your_secure_password_here (should match POSTGRES_PASSWORD)

# ------------------------------------------------------------------------------
# Service URL Configuration
# ------------------------------------------------------------------------------
# Used by: Debug utilities, health checks, pattern tracking, hook integrations
# Purpose: Configure URLs for various backend services
# Default: localhost URLs for local development
#
# Intelligence Service (archon-intelligence-adapter):
INTELLIGENCE_SERVICE_URL=http://localhost:8053

# Main Archon Server:
MAIN_SERVER_URL=http://localhost:8181

# Archon MCP Server:
ARCHON_MCP_URL=http://localhost:8051

# Qdrant Vector Database:
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_URL=http://localhost:6333

# Production deployment:
# - Set these to actual service hostnames/IPs
# - Example: INTELLIGENCE_SERVICE_URL=http://192.168.86.200:8053
# - Example: QDRANT_HOST=192.168.86.200

# ------------------------------------------------------------------------------
# Kafka Event Bus Configuration
# ------------------------------------------------------------------------------
# Used by: Event-driven intelligence, agent tracking, documentation hooks
# Purpose: Central message broker for distributed intelligence and observability
# Admin UI: http://localhost:8080 (Redpanda Console)
#
# REQUIRED: Set KAFKA_BOOTSTRAP_SERVERS based on deployment environment
# See detailed port selection guide in the "Kafka Bootstrap Servers Configuration" section below (line ~134)
#
# Quick Reference:
# - Docker internal: omninode-bridge-redpanda:9092
# - Host to Docker (production): localhost:29102 or 192.168.86.200:29102
# - Host to Docker (test): localhost:29092
KAFKA_BOOTSTRAP_SERVERS=
# Example: KAFKA_BOOTSTRAP_SERVERS=192.168.86.200:29102 or localhost:29102

# Feature Flags:
KAFKA_ENABLE_INTELLIGENCE=true          # Enable event-based intelligence queries
KAFKA_ENABLE_LOGGING=true               # Enable Kafka event logging (default: true)
ENABLE_EVENT_BASED_DISCOVERY=true       # Enable event-first pattern discovery
ENABLE_FILESYSTEM_FALLBACK=true         # Fallback to filesystem on event failure
PREFER_EVENT_PATTERNS=true              # Prefer event patterns over built-in patterns

# Performance Configuration:
KAFKA_REQUEST_TIMEOUT_MS=5000           # Request timeout (default: 5000ms)
# Target p95 response time: <100ms
# Target success rate: >95% (with fallback)

# Topics:
#
# Intelligence Topics (archon-intelligence service):
#   - dev.archon-intelligence.intelligence.code-analysis-requested.v1
#   - dev.archon-intelligence.intelligence.code-analysis-completed.v1
#   - dev.archon-intelligence.intelligence.code-analysis-failed.v1
#   Purpose: Real-time pattern discovery and intelligence queries
#
# Agent Tracking Topics (agent observability):
#   - agent-routing-decisions: Agent selection and confidence scores
#   - agent-transformation-events: Polymorphic agent transformations
#   - router-performance-metrics: Routing performance analytics
#   - agent-actions: Complete agent tool calls and execution steps
#   Purpose: Complete agent observability with replay capability
#
# Documentation Topics (git hooks):
#   - documentation-changed: Documentation file events (added, updated, deleted)
#   Purpose: Documentation change tracking for downstream processing
KAFKA_DOC_TOPIC=documentation-changed

# ------------------------------------------------------------------------------
# Kafka Bootstrap Servers Configuration (REQUIRED)
# ------------------------------------------------------------------------------
# CRITICAL: You MUST set this variable based on your deployment environment.
# No default value is provided to prevent misconfiguration.
#
# KAFKA_BOOTSTRAP_SERVERS=
#
# Port Selection Guide:
# ---------------------
# Docker Internal Communication (service-to-service):
#   KAFKA_BOOTSTRAP_SERVERS=omninode-bridge-redpanda:9092
#   ↑ Use port 9092 for containers within Docker network
#
# External Access from Host Machine:
#   KAFKA_BOOTSTRAP_SERVERS=localhost:29102
#   KAFKA_BOOTSTRAP_SERVERS=192.168.86.200:29102
#   ↑ Use port 29102 for production external access
#   ↑ Use port 29092 for test environment external access
#
# Legacy Configuration (backward compatibility):
#   KAFKA_INTELLIGENCE_BOOTSTRAP_SERVERS=<same-as-above>
#
# Common Configurations:
# ---------------------
# Local Development (Docker Compose):
#   KAFKA_BOOTSTRAP_SERVERS=omninode-bridge-redpanda:9092
#
# Local Development (Host to Docker):
#   KAFKA_BOOTSTRAP_SERVERS=localhost:29102
#
# Remote Production Server:
#   KAFKA_BOOTSTRAP_SERVERS=192.168.86.200:29102
#
# Port Reference:
# ---------------
# Port 9092  = Internal Docker network communication
# Port 29092 = External host access (test environment)
# Port 29102 = External host access (production environment)
#
# IMPORTANT: Docker port mapping varies by environment:
# - Test:       0.0.0.0:29092->29092 (see docker-compose.test.yml)
# - Production: Host-specific port mapping (often 29102)
#
# Troubleshooting:
# ----------------
# Verify Redpanda running:
#   docker ps | grep redpanda
#
# Check topics:
#   docker exec -it omninode-bridge-redpanda rpk topic list
#
# Test connectivity (adjust port based on your config):
#   kcat -L -b localhost:29102
#   kcat -L -b 192.168.86.200:29102
#
# View messages:
#   kcat -C -b localhost:29102 -t <topic-name>
#
# Requirements:
# -------------
# - Redpanda broker running (docker-compose up redpanda)
# - Event topics auto-created on first publish
# - archon-intelligence service running for intelligence queries (port 8053)
# - omniclaude_agent_consumer running for agent tracking (Docker container)
#
# Related Documentation:
# ----------------------
# - EVENT_INTELLIGENCE_INTEGRATION_PLAN.md - Integration architecture
# - CLIENT_WORKS_EVIDENCE.md - Functionality validation
# - EVENT_INTELLIGENCE_DEVELOPER_GUIDE.md - Developer integration guide
# - AGENT_OBSERVABILITY_SCHEMA.md - Agent tracking schema documentation
# - docs/KAFKA_PORT_CONFIGURATION.md - Detailed port configuration guide

# ------------------------------------------------------------------------------
# Docker Compose Deployment Configuration
# ------------------------------------------------------------------------------
# Used by: deployment/docker-compose.yml for agent-observability-consumer service
# Purpose: Connects to external omninode-bridge PostgreSQL database
# Database: PostgreSQL (omninode_bridge)
#
# REQUIRED: PostgreSQL password for omninode-bridge database
# SECURITY WARNING: MUST be changed in production!
# Production deployment: Set via environment variable or secrets management
OMNINODE_BRIDGE_POSTGRES_PASSWORD=
# Example: OMNINODE_BRIDGE_POSTGRES_PASSWORD=your_secure_password_here

# ------------------------------------------------------------------------------
# Code Generation Database Configuration (OPTIONAL)
# ------------------------------------------------------------------------------
# Used by: Node generation pipeline for template cache metrics and session tracking
# Purpose: Persists generation sessions, artifacts, and template cache analytics
# Database: PostgreSQL (omninode_bridge)
#
# NOTE: This is OPTIONAL. If not set, the system will operate with:
# - In-memory template caching only (no database persistence)
# - Generation will work normally, but metrics won't be persisted
# - A single informational message will be logged at startup
#
# Required for:
# - Template cache metrics persistence
# - Generation session tracking
# - Code generation analytics
#
# Fallback behavior:
# - Template cache works normally (in-memory)
# - No repeated warnings (single info message on initialization)
# - All generation features remain functional
#
# To enable database persistence, uncomment and set:
# POSTGRES_PASSWORD=omninode-bridge-postgres-dev-2024
#
# Connection details (shared with hook intelligence):
# - Host: localhost (POSTGRES_HOST)
# - Port: 5436 (POSTGRES_PORT)
# - Database: omninode_bridge (POSTGRES_DB)
# - User: postgres (POSTGRES_USER)

# ------------------------------------------------------------------------------
# Kafka Configuration (Documentation Hooks)
# ------------------------------------------------------------------------------
# Used by: Git hooks for documentation change tracking
# Purpose: Publish documentation events for downstream processing
# Topics:
#   - documentation-changed: Documentation file events (added, updated, deleted)
#
# NOTE: KAFKA_BOOTSTRAP_SERVERS is defined in "Kafka Event Bus Configuration" section above
# Do not redefine here - use the same value throughout the file
KAFKA_DOC_TOPIC=documentation-changed

# Optional: Enable/disable git hook validation
# Set to 'true' to validate documentation before push
GIT_HOOK_VALIDATE_DOCS=false

# ------------------------------------------------------------------------------
# Manifest Cache Configuration
# ------------------------------------------------------------------------------
# Used by: ManifestInjector (agents/lib/manifest_injector.py)
# Purpose: Configurable TTL for pattern/infrastructure/model caching
# Default: 300 seconds (5 minutes)
#
# Per-query-type TTLs (relative to default):
#   - patterns: 3x default (15 minutes) - patterns are relatively static
#   - infrastructure: 2x default (10 minutes) - changes infrequently
#   - models: 3x default (15 minutes) - relatively static
#   - database_schemas: 1x default (5 minutes)
#   - debug_intelligence: 0.5x default (2.5 minutes) - changes frequently
#
# Performance targets:
#   - 60%+ cache hit rate
#   - <5ms cache query time
#   - 30-50% overall query time reduction
MANIFEST_CACHE_TTL_SECONDS=300

# ------------------------------------------------------------------------------
# Kafka Configuration (Event-Based Intelligence)
# ------------------------------------------------------------------------------
# Used by: IntelligenceEventClient (agents/lib/intelligence_event_client.py)
# Purpose: Event-driven pattern discovery from omniarchon intelligence service
# Integration: Replaces hard-coded filesystem paths with dynamic discovery
#
# Configuration:
# NOTE: KAFKA_INTELLIGENCE_BOOTSTRAP_SERVERS uses same value as KAFKA_BOOTSTRAP_SERVERS
# See "Kafka Bootstrap Servers Configuration" section above for port selection guide
# Do not redefine here - use the same value throughout the file
KAFKA_INTELLIGENCE_BOOTSTRAP_SERVERS=
# Example: KAFKA_INTELLIGENCE_BOOTSTRAP_SERVERS=192.168.86.200:29102 (should match KAFKA_BOOTSTRAP_SERVERS)

KAFKA_ENABLE_INTELLIGENCE=true
ENABLE_EVENT_BASED_DISCOVERY=true
ENABLE_FILESYSTEM_FALLBACK=true
PREFER_EVENT_PATTERNS=true
KAFKA_REQUEST_TIMEOUT_MS=5000

# Event Topics (ONEX architecture):
#   - dev.archon-intelligence.intelligence.code-analysis-requested.v1
#   - dev.archon-intelligence.intelligence.code-analysis-completed.v1
#   - dev.archon-intelligence.intelligence.code-analysis-failed.v1

# Port Mapping:
#   - External (host): localhost:9092 or 192.168.86.200:9092
#   - Docker internal: omninode-bridge-redpanda:9092
#   - Redpanda Admin UI: http://localhost:8080

# Requirements:
#   - omniarchon intelligence service running (archon-intelligence on port 8053)
#   - Redpanda broker running (docker-compose up redpanda)
#   - Event topics created (auto-created on first publish)

# Feature Flags:
#   - KAFKA_ENABLE_INTELLIGENCE: Master switch for event-based intelligence
#   - ENABLE_EVENT_BASED_DISCOVERY: Enable event-first pattern discovery
#   - ENABLE_FILESYSTEM_FALLBACK: Fallback to filesystem on event failure
#   - PREFER_EVENT_PATTERNS: Prefer event patterns over built-in patterns

# Performance:
#   - Request timeout: 5000ms default (configurable)
#   - Target p95: <100ms response time
#   - Success rate: >95% (with fallback to filesystem)

# Troubleshooting:
#   - Verify Redpanda running: docker ps | grep redpanda
#   - Check topics: docker exec -it <redpanda-container> rpk topic list
#   - Test connectivity: poetry run python -c "from agents.lib.intelligence_event_client import IntelligenceEventClient; import asyncio; asyncio.run(IntelligenceEventClient().start())"
#   - See CLIENT_WORKS_EVIDENCE.md for validation evidence

# Related Documentation:
#   - EVENT_INTELLIGENCE_INTEGRATION_PLAN.md - Integration architecture
#   - CLIENT_WORKS_EVIDENCE.md - Functionality validation
#   - EVENT_INTELLIGENCE_DEVELOPER_GUIDE.md - Developer integration guide

# ------------------------------------------------------------------------------
# Development Repository Paths (OPTIONAL)
# ------------------------------------------------------------------------------
# Used by: Code refiner (agents/lib/code_refiner.py) for production pattern discovery
# Purpose: Enables code refinement with production ONEX patterns from sibling repositories
# Default: Automatically resolves to sibling directories (../omniarchon, ../omninode_bridge)
#
# Only set these if:
# - Repositories are not in standard sibling location
# - Using custom directory structure
# - Running in CI/CD with specific paths
#
# If not set, defaults to:
# - OMNIARCHON_PATH: ../omniarchon (relative to omniclaude)
# - OMNINODE_BRIDGE_PATH: ../omninode_bridge (relative to omniclaude)
#
# OMNIARCHON_PATH=/custom/path/to/omniarchon
# OMNINODE_BRIDGE_PATH=/custom/path/to/omninode_bridge

# ------------------------------------------------------------------------------
# Security Best Practices
# ------------------------------------------------------------------------------
# 1. Never commit .env files to version control
# 2. Rotate keys every 30-90 days (see SECURITY_KEY_ROTATION.md)
# 3. Use separate keys for development and production
# 4. Enable IP restrictions in provider dashboards
# 5. Set usage quotas to limit damage from leaks
# 6. Monitor API usage regularly
#
# See SECURITY_KEY_ROTATION.md for:
# - How to obtain API keys
# - Step-by-step rotation procedures
# - Testing new keys
# - Troubleshooting common issues
# ------------------------------------------------------------------------------
