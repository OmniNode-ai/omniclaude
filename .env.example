# OmniClaude Environment Configuration
# ==============================================================================
# IMPORTANT: Copy this file to .env and replace placeholder values with actual values
# Never commit .env to version control!
#
# Setup Instructions:
# 1. cp .env.example .env
# 2. Edit .env with your actual API keys and configuration
# 3. source .env (or use direnv)
# 4. Verify: echo $GEMINI_API_KEY
#
# See SECURITY_KEY_ROTATION.md for detailed setup and rotation procedures
# ==============================================================================

# ==============================================================================
# ENVIRONMENT CONFIGURATION
# ==============================================================================
# Environment type: development, test, or production
#
# SECURITY NOTE: This setting affects service binding addresses for security:
# - development: Services bind to 0.0.0.0 (all interfaces) for Docker/debugging
# - production/test: Services bind to 127.0.0.1 (localhost only) for security
#
# To override host binding, set: ROUTING_ADAPTER_HOST=<your-ip>
ENVIRONMENT=development

# Container naming prefix for Docker services
CONTAINER_PREFIX=omniclaude

# ==============================================================================
# EXTERNAL SERVICE DISCOVERY (from omniarchon)
# ==============================================================================
# These services are provided by the omniarchon repository
# Default: Services running on 192.168.86.101
# Update these URLs if services are deployed elsewhere
#
# Archon Intelligence API - Code quality, pattern discovery, RAG queries
ARCHON_INTELLIGENCE_URL=http://192.168.86.101:8053

# Archon Search API - Vector search, semantic search
ARCHON_SEARCH_URL=http://192.168.86.101:8055

# Archon Bridge API - Bridge services between systems
ARCHON_BRIDGE_URL=http://192.168.86.101:8054

# Archon MCP Server - Model Context Protocol server
ARCHON_MCP_URL=http://192.168.86.101:8051

# Legacy alias for intelligence service (for backward compatibility)
INTELLIGENCE_SERVICE_URL=${ARCHON_INTELLIGENCE_URL}

# Archon Server (if different from intelligence)
MAIN_SERVER_URL=http://192.168.86.101:8181

# ==============================================================================
# SHARED INFRASTRUCTURE (from omninode_bridge)
# ==============================================================================
# These services are provided by the omninode_bridge repository
# Default: Infrastructure running on 192.168.86.200
#
# ------------------------------------------------------------------------------
# Kafka/Redpanda Event Bus
# ------------------------------------------------------------------------------
# Central message broker for distributed intelligence and observability
# Admin UI: http://192.168.86.200:8080 (Redpanda Console)
#
# IMPORTANT: Port selection depends on your deployment context
#
# For Docker services (containers in docker-compose):
#   Use hostname 'omninode-bridge-redpanda' with port 9092
#   KAFKA_BOOTSTRAP_SERVERS=omninode-bridge-redpanda:9092
#
# For host scripts (running on your local machine):
#   Use internal Docker network hostname with port 9092
KAFKA_BOOTSTRAP_SERVERS=omninode-bridge-redpanda:9092
#
# For remote server (SSH'd into 192.168.86.200):
#   KAFKA_BOOTSTRAP_SERVERS=localhost:29092
#
# Topics Used:
#   Intelligence: dev.archon-intelligence.intelligence.*
#   Agent Tracking: agent-routing-decisions, agent-transformation-events
#   Documentation: documentation-changed

# Legacy alias for backward compatibility
KAFKA_INTELLIGENCE_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}

# Feature Flags
KAFKA_ENABLE_INTELLIGENCE=true          # Enable event-based intelligence queries
KAFKA_ENABLE_LOGGING=true               # Enable Kafka event logging
ENABLE_EVENT_BASED_DISCOVERY=true       # Enable event-first pattern discovery
ENABLE_FILESYSTEM_FALLBACK=true         # Fallback to filesystem on event failure
PREFER_EVENT_PATTERNS=true              # Prefer event patterns over built-in patterns

# Performance Configuration
KAFKA_REQUEST_TIMEOUT_MS=5000           # Request timeout in milliseconds

# Documentation change tracking topic
KAFKA_DOC_TOPIC=documentation-changed

# ------------------------------------------------------------------------------
# PostgreSQL Database - Local Application
# ------------------------------------------------------------------------------
# Local containerized PostgreSQL for application-specific data
# Used by: app, postgres services in docker-compose.yml
# Database: omniclaude (local, containerized)
#
APP_POSTGRES_HOST=postgres
APP_POSTGRES_PORT=5432
APP_POSTGRES_INTERNAL_PORT=5432
APP_POSTGRES_DATABASE=omniclaude
APP_POSTGRES_USER=omniclaude
APP_POSTGRES_PASSWORD=  # REQUIRED: Set your local app database password

# ------------------------------------------------------------------------------
# PostgreSQL Database - Shared Bridge
# ------------------------------------------------------------------------------
# Shared database for agent tracking, pattern storage, observability
# Used by: routing-adapter, agent-observability-consumer, archon-router-consumer
# Database: omninode_bridge (34+ tables)
#
# Connection details for external access from host:
POSTGRES_HOST=192.168.86.200
POSTGRES_PORT=5436
POSTGRES_DATABASE=omninode_bridge
POSTGRES_USER=postgres
POSTGRES_PASSWORD=  # REQUIRED: Set your actual password in .env (NEVER commit)

# ------------------------------------------------------------------------------
# Password Aliases (DEPRECATED - Migration Plan)
# ------------------------------------------------------------------------------
# DEPRECATION NOTICE: Multiple password aliases exist creating maintenance risk
# during password rotation. All services should migrate to POSTGRES_PASSWORD.
#
# Timeline: These aliases will be removed in v2.0 (estimated 2025-Q2)
#
# Current Service Usage:
#   POSTGRES_DB → Used by: Kafka consumer services, legacy event processors
#   DB_PASSWORD → Used by: Legacy Python scripts, standalone utilities
#   OMNINODE_BRIDGE_POSTGRES_PASSWORD → Used by: Bridge adapter, cross-repo services
#
# Migration Instructions:
#   1. Search codebase for each alias: grep -r "POSTGRES_DB\|DB_PASSWORD\|OMNINODE_BRIDGE"
#   2. Replace with POSTGRES_PASSWORD in all service code
#   3. Test each service after migration
#   4. Remove aliases from .env after all services updated
#
# Security Impact:
#   - Password rotation requires updating multiple aliases (error-prone)
#   - Inconsistent naming increases audit complexity
#   - Migration to single variable improves security hygiene
#
POSTGRES_DB=${POSTGRES_DATABASE}                              # DEPRECATED (v2.0)
DB_PASSWORD=${POSTGRES_PASSWORD}                              # DEPRECATED (v2.0)
OMNINODE_BRIDGE_POSTGRES_PASSWORD=${POSTGRES_PASSWORD}        # DEPRECATED (v2.0)

# SECURITY WARNING: Change default password in production!
#
# For Docker services (containers in docker-compose):
#   POSTGRES_HOST=omninode-bridge-postgres
#   POSTGRES_PORT=5432
#
# Tables include:
#   - agent_routing_decisions: Agent selection and confidence scores
#   - agent_manifest_injections: Complete manifest snapshots
#   - agent_execution_logs: Execution lifecycle tracking
#   - pattern_quality_metrics: Pattern quality scores
#   - And 30+ more observability tables

# ==============================================================================
# AI PROVIDER API KEYS
# ==============================================================================
#
# ------------------------------------------------------------------------------
# Google Gemini API Configuration
# ------------------------------------------------------------------------------
# Used by: Multi-provider support, AI quorum validation
# Get your key: https://console.cloud.google.com/apis/credentials
# Required for: Gemini Pro, Gemini Flash, Gemini 2.5 Flash providers
# Permissions: Enable "Generative Language API"
# Rate Limits: Check Google Cloud Console for your tier
GEMINI_API_KEY=  # REQUIRED: Set your actual API key in .env

# Google API Key (Pydantic AI Integration)
# Note: This should be the same as GEMINI_API_KEY for Pydantic AI compatibility
GOOGLE_API_KEY=${GEMINI_API_KEY}

# ------------------------------------------------------------------------------
# Z.ai API Configuration
# ------------------------------------------------------------------------------
# Used by: GLM model support, high-concurrency operations
# Get your key: https://z.ai/dashboard
# Required for: Z.ai provider (GLM-4.5-Air, GLM-4.5, GLM-4.6)
# Rate Limits:
#   - GLM-4.5-Air: 5 concurrent requests
#   - GLM-4.5: 20 concurrent requests
#   - GLM-4.6: 10 concurrent requests
ZAI_API_KEY=  # REQUIRED: Set your actual API key in .env

# ==============================================================================
# ALERTING & NOTIFICATIONS
# ==============================================================================
#
# ------------------------------------------------------------------------------
# Slack Webhook Configuration
# ------------------------------------------------------------------------------
# Used by: SlackNotifier (agents/lib/slack_notifier.py)
# Purpose: Fail-fast error notifications with throttling
# Get your webhook: https://api.slack.com/messaging/webhooks
#
# Setup Instructions:
#   1. Go to https://api.slack.com/apps
#   2. Create a new app or select existing app
#   3. Enable "Incoming Webhooks"
#   4. Add webhook to your desired channel
#   5. Copy webhook URL and paste below
#
# Features:
#   - Opt-in: Only sends if URL is configured (leave empty to disable)
#   - Throttling: Max 1 notification per error type per throttle window
#   - Non-blocking: Notification failures don't break main flow
#   - Rich context: Error type, message, stack trace, service name, timestamp
#
# Integration Points:
#   - Kafka connection failures (routing_event_client)
#   - Routing failures (agent_router_event_service)
#   - Configuration validation failures (config/settings.py)
#   - Database connection errors
#
SLACK_WEBHOOK_URL=  # OPTIONAL: Set to enable Slack notifications (leave empty to disable)

# Throttle window in seconds (default: 300 = 5 minutes)
# Max 1 notification per error type per window to prevent spam
# Set to 0 to disable throttling (not recommended)
SLACK_NOTIFICATION_THROTTLE_SECONDS=300

# ==============================================================================
# LOCAL SERVICES CONFIGURATION
# ==============================================================================
# Services running locally on your development machine
#
# ------------------------------------------------------------------------------
# Qdrant Vector Database
# ------------------------------------------------------------------------------
# Local vector database for pattern storage and semantic search
# Collections: code_patterns, execution_patterns, workflow_events
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_URL=http://localhost:6333

# Health check: curl http://localhost:6333/collections

# ------------------------------------------------------------------------------
# Valkey Caching (Redis-compatible)
# ------------------------------------------------------------------------------
# Used by: IntelligenceCache (agents/lib/intelligence_cache.py)
# Purpose: Distributed, persistent caching for intelligence queries
# Service: archon-valkey (Redis-compatible key-value store)
#
# Architecture:
#   - Two-tier caching: Valkey (distributed) → In-memory (local)
#   - Valkey checked first for cross-process cache hits
#   - Results stored in both caches after query
#
ENABLE_INTELLIGENCE_CACHE=true

# ------------------------------------------------------------------------------
# Valkey/Redis Authentication
# ------------------------------------------------------------------------------
# Choose configuration based on your environment:
#
# DEVELOPMENT (local trusted network):
#   VALKEY_PASSWORD=  # Empty = no authentication
#   ✓ Acceptable in isolated dev environment with Docker network isolation
#   ✓ Simplifies local debugging and development workflow
#   ✗ NEVER use this in production or exposed environments
#
# PRODUCTION (exposed environment):
#   VALKEY_PASSWORD=your-strong-password-here  # REQUIRED for security
#   ✓ Minimum 16 characters (alphanumeric + special chars)
#   ✓ Change default passwords immediately
#   ✓ Never expose port 6379 outside Docker network without auth
#
# Set according to your environment:
VALKEY_PASSWORD=  # Empty for dev, strong password for production

# Valkey Connection URL
# Automatically uses VALKEY_PASSWORD if set, empty password if not
# Default behavior:
#   Development: redis://:@archon-valkey:6379/0 (no password, VALKEY_PASSWORD empty)
#   Production: redis://:${VALKEY_PASSWORD}@archon-valkey:6379/0 (with password)
#
VALKEY_URL=redis://:${VALKEY_PASSWORD:-}@archon-valkey:6379/0
#
# Alternative configurations:
#   For localhost development (outside Docker):
#     VALKEY_URL=redis://:${VALKEY_PASSWORD:-}@localhost:6379/0
#   For different database number:
#     VALKEY_URL=redis://:${VALKEY_PASSWORD:-}@archon-valkey:6379/1

# Cache TTLs (seconds) - Per-operation-type configuration:
CACHE_TTL_PATTERNS=300        # 5 minutes - pattern discovery results
CACHE_TTL_INFRASTRUCTURE=3600 # 1 hour - infrastructure topology
CACHE_TTL_SCHEMAS=1800        # 30 minutes - database schemas

# Performance Targets:
#   - Query time reduction: 7,500ms → 1,500ms (with 60% cache hit rate)
#   - Cache hit rate: >60%
#   - Cache lookup time: <10ms p95

# Troubleshooting:
#   docker ps | grep archon-valkey
#   redis-cli -h localhost -p 6379 ping
#   redis-cli -h localhost -p 6379 keys "intelligence:*"

# ==============================================================================
# FEATURE FLAGS & OPTIMIZATION
# ==============================================================================
#
# ------------------------------------------------------------------------------
# Manifest Cache Configuration
# ------------------------------------------------------------------------------
# Used by: ManifestInjector (agents/lib/manifest_injector.py)
# Purpose: Configurable TTL for pattern/infrastructure/model caching
# Default: 300 seconds (5 minutes)
#
# Per-query-type TTLs (relative to default):
#   - patterns: 3x default (15 minutes) - patterns are relatively static
#   - infrastructure: 2x default (10 minutes) - changes infrequently
#   - models: 3x default (15 minutes) - relatively static
#   - database_schemas: 1x default (5 minutes)
#   - debug_intelligence: 0.5x default (2.5 minutes) - changes frequently
MANIFEST_CACHE_TTL_SECONDS=300

# ------------------------------------------------------------------------------
# Pattern Quality Filtering (Phase 2 Optimization)
# ------------------------------------------------------------------------------
# Used by: ManifestInjector (agents/lib/manifest_injector.py)
# Purpose: Filter low-quality patterns from manifest injection
# Integration: PatternQualityScorer evaluates patterns across 5 dimensions
#
# Scoring Dimensions:
# 1. Code Completeness (0-1.0): Has meaningful code vs stubs
# 2. Documentation Quality (0-1.0): Docstrings, comments, type hints
# 3. ONEX Compliance (0-1.0): Follows ONEX architecture patterns
# 4. Metadata Richness (0-1.0): Use cases, examples, node types
# 5. Complexity Appropriateness (0-1.0): Complexity matches use case
#
ENABLE_PATTERN_QUALITY_FILTER=false  # Set to 'true' to enable quality filtering
MIN_PATTERN_QUALITY=0.5              # 0.0-1.0 threshold (0.5 = fair quality minimum)

# Quality Thresholds:
#   0.9+ = Excellent (production-ready, well-documented)
#   0.7-0.9 = Good (functional, adequately documented)
#   0.5-0.7 = Fair (usable but needs improvement)
#   <0.5 = Poor (filtered out by default)

# ==============================================================================
# CODE GENERATION CONFIGURATION
# ==============================================================================
#
# ------------------------------------------------------------------------------
# Code Generation Service
# ------------------------------------------------------------------------------
# Used by: CodeGenerator (agents/parallel_execution/agent_code_generator.py)
# Purpose: Configure automatic code generation behavior and quality gates
#
# Kafka consumer group for code generation event processing
CODEGEN_CONSUMER_GROUP=omniclaude-codegen

# ------------------------------------------------------------------------------
# Generation Control Flags
# ------------------------------------------------------------------------------
# Enable/disable generation of specific code artifacts
# All flags default to true except CODEGEN_GENERATE_BUSINESS_LOGIC
#
CODEGEN_GENERATE_CONTRACTS=true        # Generate Pydantic contract models
CODEGEN_GENERATE_MODELS=true           # Generate data models
CODEGEN_GENERATE_ENUMS=true            # Generate enum types
CODEGEN_GENERATE_BUSINESS_LOGIC=false  # Generate business logic (starts with stubs)
CODEGEN_GENERATE_TESTS=true            # Generate unit tests

# ------------------------------------------------------------------------------
# Quality Gates
# ------------------------------------------------------------------------------
# Quality thresholds for generated code validation
# Values: 0.0-1.0 (0.0 = no requirements, 1.0 = perfect)
#
CODEGEN_QUALITY_THRESHOLD=0.8              # Minimum code quality threshold
CODEGEN_ONEX_COMPLIANCE_THRESHOLD=0.7      # Minimum ONEX compliance threshold
CODEGEN_REQUIRE_HUMAN_REVIEW=true          # Require human review before deployment

# ------------------------------------------------------------------------------
# Intelligence Timeouts
# ------------------------------------------------------------------------------
# Timeouts for AI-powered analysis and validation (in seconds)
#
CODEGEN_ANALYSIS_TIMEOUT_SECONDS=30        # Code analysis timeout
CODEGEN_VALIDATION_TIMEOUT_SECONDS=20      # Validation timeout

# ------------------------------------------------------------------------------
# Mixin Configuration
# ------------------------------------------------------------------------------
# Control automatic selection of code mixins/patterns
#
CODEGEN_AUTO_SELECT_MIXINS=true              # Auto-select appropriate mixins
CODEGEN_MIXIN_CONFIDENCE_THRESHOLD=0.7       # Minimum mixin confidence (0.0-1.0)

# ==============================================================================
# OPTIONAL CONFIGURATION
# ==============================================================================
#
# ------------------------------------------------------------------------------
# Development Repository Paths
# ------------------------------------------------------------------------------
# Used by: Code refiner (agents/lib/code_refiner.py)
# Purpose: Production pattern discovery from sibling repositories
# Default: Automatically resolves to ../omniarchon, ../omninode_bridge
#
# Only set these if repositories are not in standard sibling location:
# OMNIARCHON_PATH=/custom/path/to/omniarchon
# OMNINODE_BRIDGE_PATH=/custom/path/to/omninode_bridge

# ------------------------------------------------------------------------------
# Security Configuration
# ------------------------------------------------------------------------------
# Secret key for application security (JWT, session encryption, etc.)
# Generate with: openssl rand -base64 32
SECRET_KEY=  # REQUIRED: Set a strong secret key (minimum 32 characters)

# Grafana admin password for monitoring dashboard
# Default username: admin
# SECURITY: Change this immediately in production!
GRAFANA_ADMIN_PASSWORD=  # REQUIRED: Set a strong password

# ------------------------------------------------------------------------------
# Git Hooks Configuration
# ------------------------------------------------------------------------------
# Used by: Git hooks for documentation validation
# Purpose: Enable/disable documentation validation before push
GIT_HOOK_VALIDATE_DOCS=false

# ==============================================================================
# SECURITY BEST PRACTICES
# ==============================================================================
# 1. Never commit .env files to version control
# 2. Rotate keys every 30-90 days (see SECURITY_KEY_ROTATION.md)
# 3. Use separate keys for development and production
# 4. Enable IP restrictions in provider dashboards
# 5. Set usage quotas to limit damage from leaks
# 6. Monitor API usage regularly
# 7. Change ALL default passwords immediately in production
# 8. Use environment variables for all sensitive configuration
#
# See SECURITY_KEY_ROTATION.md for:
# - How to obtain API keys from provider dashboards
# - Step-by-step rotation procedures
# - Testing new keys
# - Troubleshooting common issues
# ==============================================================================

# ==============================================================================
# TROUBLESHOOTING
# ==============================================================================
# Health Check:
#   ./scripts/health_check.sh
#
# Verify Services:
#   curl http://192.168.86.101:8053/health  # Archon Intelligence
#   curl http://localhost:6333/collections  # Qdrant
#
# Database Connection (ALWAYS source .env first):
#   source .env
#   psql -h ${POSTGRES_HOST} -p ${POSTGRES_PORT} -U ${POSTGRES_USER} -d ${POSTGRES_DATABASE}
#
# Kafka Topics:
#   docker exec -it omninode-bridge-redpanda rpk topic list
#
# Service Logs:
#   docker logs -f archon-intelligence
#   docker logs -f omninode-bridge-redpanda
#
# See CLAUDE.md for complete troubleshooting guide
# ==============================================================================
