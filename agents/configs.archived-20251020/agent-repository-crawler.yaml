agent_domain: repository_crawler
agent_purpose: Repository crawler specialist for discovering, processing, and indexing
  all relevant documents across codebases with intelligence service integration
agent_title: "üîç Repository Crawler"
agent_description: Repository crawler specialist for discovering, processing, and
  indexing all relevant documents across codebases with intelligence service integration
agent_context: setup
domain_query: repository setup best practices
implementation_query: project initialization patterns
match_count: 5
confidence_threshold: 0.6
knowledge_capture_level: comprehensive

capabilities:
  mandatory_functions: true
  template_system: true
  enhanced_patterns: true
  quality_intelligence: true
  # Intelligence Capabilities (Phase 5)
  coverage_assessment: true         # Evaluate discovery completeness and gaps
  discovery_quality_scoring: true   # Score quality of discovered files and patterns
  pattern_detection: true           # Identify repository structure patterns
  completeness_validation: true     # Verify all relevant files were discovered
  crawl_intelligence: true          # Intelligent crawling strategies and optimization
  freshness_tracking: true          # Track file freshness and update patterns
  dependency_mapping: true          # Map file dependencies and relationships
  metadata_extraction: true         # Extract and analyze file metadata

archon_mcp_enabled: true
correlation_tracking: true
parallel_capable: true

triggers:
  - crawl repository
  - discover repository structure
  - index codebase
  - scan project files
  - analyze repository contents
  - map repository
  - explore codebase
  - discover project structure
  # Intelligence-specific triggers (Phase 5)
  - assess repository coverage
  - evaluate discovery quality
  - validate crawling completeness
  - detect repository patterns
  - analyze crawling efficiency
  - optimize discovery strategy
  - track file freshness
  - map file dependencies

intelligence_integration:
  # Pre-Execution Phase
  pre_execution:
    - action: analyze_repository_structure
      tool: mcp__archon__research
      params:
        query: "repository structure analysis best practices"
        context: "architecture"
        max_results_per_source: 5
      purpose: "Learn optimal crawling strategies and patterns"
      quality_gate:
        min_confidence: 0.7
        required_sources: ["rag_search", "vector_search"]

    - action: establish_coverage_baseline
      tool: mcp__archon__establish_performance_baseline
      params:
        operation_name: "repository_crawl"
        metrics:
          files_discovered: 0
          directories_scanned: 0
          coverage_percentage: 0.0
          quality_score: 0.0
      purpose: "Track crawling performance and coverage"

    - action: query_successful_crawl_patterns
      tool: mcp__archon__cross_project_rag_query
      params:
        query: "successful repository crawling patterns and strategies"
        project_group: "archon"
        match_count: 8
      purpose: "Learn from previous successful crawls"

    - action: identify_repository_type
      tool: mcp__serena__list_dir
      params:
        relative_path: "."
        recursive: false
      purpose: "Identify repository type and structure"
      quality_gate:
        validation: "verify_root_indicators"
        min_indicators: 2

  # During Execution Phase
  during_execution:
    - action: assess_discovery_quality
      tool: mcp__archon__assess_code_quality
      params:
        content: "{discovered_files_summary}"
        source_path: "discovery_report.txt"
        language: "text"
      purpose: "Evaluate quality of discovered files"
      trigger: "after_each_directory"
      quality_gate:
        min_quality_score: 0.6
        max_anti_patterns: 3

    - action: validate_coverage_progress
      tool: mcp__archon__monitor_performance_trends
      params:
        time_window_hours: 1
        include_predictions: true
      purpose: "Track crawling progress and predict completion"
      trigger: "every_100_files"

    - action: detect_repository_patterns
      tool: mcp__archon__get_quality_patterns
      params:
        content: "{repository_structure}"
        pattern_type: "best_practices"
      purpose: "Identify patterns in repository structure"
      trigger: "after_major_directory"

    - action: check_architectural_patterns
      tool: mcp__archon__check_architectural_compliance
      params:
        content: "{directory_structure}"
        architecture_type: "onex"
      purpose: "Verify ONEX architectural patterns"
      trigger: "when_onex_detected"

    - action: track_file_freshness
      tool: mcp__archon__analyze_document_freshness_tool
      params:
        path: "{current_directory}"
        recursive: true
        include_patterns: ["*.py", "*.md", "*.yaml", "*.json"]
      purpose: "Track file freshness for prioritization"
      trigger: "per_directory"

    - action: map_file_dependencies
      tool: mcp__serena__find_symbol
      params:
        name_path: "import"
        relative_path: "{current_file}"
        depth: 1
      purpose: "Build dependency graph"
      trigger: "for_code_files"

  # Post-Execution Phase
  post_execution:
    - action: generate_coverage_report
      tool: mcp__archon__get_optimization_report
      params:
        time_window_hours: 1
      purpose: "Generate comprehensive crawling report"
      quality_gate:
        min_coverage: 0.85
        min_quality_score: 0.7

    - action: validate_completeness
      tool: mcp__archon__analyze_document_quality
      params:
        content: "{crawl_summary}"
        document_type: "markdown"
        check_completeness: true
      purpose: "Verify crawl completeness"
      quality_gate:
        min_completeness: 0.9
        required_sections: ["files_discovered", "patterns_detected", "coverage_metrics"]

    - action: identify_missed_areas
      tool: mcp__archon__identify_optimization_opportunities
      params:
        operation_name: "repository_crawl"
      purpose: "Find areas not properly crawled"

    - action: track_crawl_pattern
      tool: mcp__archon__cross_project_rag_query
      params:
        query: "repository crawling success patterns"
        project_group: "all"
        match_count: 5
      purpose: "Contribute to pattern learning"

    - action: generate_freshness_stats
      tool: mcp__archon__get_freshness_stats_tool
      params:
        base_path: "{repository_root}"
      purpose: "Generate file freshness statistics"

    - action: create_dependency_map
      tool: mcp__archon__search_entity_relationships
      params:
        entity_id: "{repository_root_entity}"
        max_depth: 3
      purpose: "Create complete dependency map"

    - action: assess_overall_quality
      tool: mcp__archon__assess_code_quality
      params:
        content: "{final_discovery_report}"
        source_path: "discovery_summary.md"
        language: "markdown"
      purpose: "Final quality assessment"
      quality_gate:
        min_quality_score: 0.75
        max_issues: 5

quality_gates:
  coverage:
    min_files_discovered: 10
    min_coverage_percentage: 0.85
    max_missed_directories: 2
    min_pattern_matches: 3

  discovery_quality:
    min_quality_score: 0.7
    max_anti_patterns: 5
    min_architectural_compliance: 0.6
    required_metadata_fields: ["path", "type", "size", "modified"]

  completeness:
    required_file_types: ["python", "markdown", "config", "docs"]
    min_files_per_type: 1
    max_empty_directories: 3
    verify_root_files: true

  performance:
    max_crawl_duration_seconds: 300
    min_files_per_second: 2
    max_memory_mb: 500
    max_retries: 3

pattern_learning:
  track_patterns:
    - pattern_type: "repository_structure"
      metadata:
        - "framework_type"
        - "project_size"
        - "directory_depth"
        - "file_distribution"

    - pattern_type: "crawling_strategy"
      metadata:
        - "traversal_order"
        - "priority_rules"
        - "exclusion_patterns"
        - "performance_metrics"

    - pattern_type: "discovery_quality"
      metadata:
        - "coverage_achieved"
        - "patterns_detected"
        - "completeness_score"
        - "quality_metrics"

  learning_objectives:
    - "Optimize crawling strategies per repository type"
    - "Improve coverage prediction accuracy"
    - "Enhance pattern detection effectiveness"
    - "Reduce redundant file processing"

  success_metrics:
    - metric: "coverage_percentage"
      target: 0.95
      weight: 0.3

    - metric: "discovery_quality_score"
      target: 0.85
      weight: 0.25

    - metric: "pattern_detection_accuracy"
      target: 0.90
      weight: 0.25

    - metric: "crawl_efficiency"
      target: 0.80
      weight: 0.20

workflow_patterns:
  comprehensive_crawl:
    steps:
      - "Pre-execution intelligence gathering"
      - "Repository type identification"
      - "Coverage baseline establishment"
      - "Directory traversal with quality checks"
      - "Pattern detection and validation"
      - "Dependency mapping"
      - "Freshness tracking"
      - "Completeness validation"
      - "Post-execution reporting"

  incremental_update:
    steps:
      - "Check freshness statistics"
      - "Identify stale files"
      - "Targeted re-crawling"
      - "Dependency update"
      - "Pattern re-validation"
      - "Coverage verification"

  pattern_focused:
    steps:
      - "Query known patterns"
      - "Selective directory crawling"
      - "Pattern validation"
      - "Architectural compliance check"
      - "Pattern contribution"

intelligence_metrics:
  quality_scoring:
    - "File type distribution score"
    - "Pattern detection accuracy"
    - "Metadata completeness"
    - "Dependency graph completeness"

  coverage_metrics:
    - "Percentage of files discovered"
    - "Directory depth coverage"
    - "File type coverage"
    - "Missing file estimation"

  performance_metrics:
    - "Files processed per second"
    - "Average directory scan time"
    - "Memory usage efficiency"
    - "Cache hit rate"

  pattern_metrics:
    - "Patterns detected count"
    - "Pattern match confidence"
    - "Architectural compliance score"
    - "Anti-pattern detection count"

error_handling:
  intelligence_failures:
    - scenario: "Quality assessment unavailable"
      fallback: "Continue with basic crawling"
      alert: true

    - scenario: "Pattern detection fails"
      fallback: "Use manual pattern matching"
      alert: false

    - scenario: "Coverage validation timeout"
      fallback: "Use estimated coverage"
      alert: true

  recovery_strategies:
    - "Resume from last successful directory"
    - "Skip problematic files with logging"
    - "Retry with reduced concurrency"
    - "Fall back to sequential crawling"

output_artifacts:
  reports:
    - name: "repository_structure.json"
      description: "Complete repository structure map"
      quality_gate: true

    - name: "coverage_report.md"
      description: "Crawling coverage analysis"
      quality_gate: true

    - name: "pattern_analysis.json"
      description: "Detected patterns and anti-patterns"
      quality_gate: false

    - name: "dependency_graph.json"
      description: "File dependency relationships"
      quality_gate: false

    - name: "freshness_report.md"
      description: "File freshness statistics"
      quality_gate: false

  metrics:
    - "total_files_discovered"
    - "total_directories_scanned"
    - "coverage_percentage"
    - "quality_score"
    - "patterns_detected"
    - "crawl_duration_seconds"
