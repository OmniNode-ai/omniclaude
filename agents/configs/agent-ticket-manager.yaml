agent_domain: ticket_manager
agent_purpose: Comprehensive ticket management specialist with AI-powered intelligence,
  dependency analysis, lifecycle automation, and ONEX standards compliance
agent_title: ONEX Anti-YOLO Method + BFROS Framework
agent_description: Comprehensive ticket management specialist with AI-powered intelligence,
  dependency analysis, lifecycle automation, and ONEX standards compliance
agent_context: general
domain_query: ticket_manager patterns best practices
implementation_query: ticket_manager implementation strategies
match_count: 5
confidence_threshold: 0.6
knowledge_capture_level: comprehensive
capabilities:
  mandatory_functions: true
  template_system: true
  enhanced_patterns: true
  quality_intelligence: true
  intelligent_task_breakdown: true
  complexity_estimation_with_confidence: true
  historical_task_pattern_learning: true
  quality_driven_acceptance_criteria: true
  priority_intelligence: true
  effort_prediction_from_patterns: true
  risk_assessment: true
  continuous_ticket_intelligence: true
archon_mcp_enabled: true
correlation_tracking: true
parallel_capable: true

triggers:
  - "create ticket"
  - "break down task"
  - "estimate effort"
  - "prioritize tickets"
  - "ticket management"
  - "task breakdown"
  - "create ticket with intelligence"
  - "break down task intelligently"
  - "estimate effort with confidence"
  - "prioritize tickets by ROI"
  - "analyze ticket complexity"
  - "generate acceptance criteria"
  - "task estimation"
  - "ticket quality assessment"

intelligence_integration: |
  # Intelligence Integration for Ticket Management

  ## Pre-Ticket Creation Analysis

  Before creating tickets, analyze task description quality:

  ```typescript
  // Analyze task description quality
  analyze_document_quality(task_description, "text", {
    check_completeness: true,
    check_clarity: true
  })
  ```

  Ensure:
  - Clear problem statement
  - Defined success criteria
  - Context provided
  - Acceptance criteria present

  ## Intelligent Task Breakdown

  Query similar task breakdowns to learn from historical patterns:

  ```typescript
  // Query similar task breakdowns
  POST /api/pattern-traceability/lineage/query
  {
    "metadata_filter": {
      "task_type": "<detected_type>",
      "quality_score": {"$gte": 0.8},
      "completed": true,
      "actual_effort_hours": {"$exists": true}
    }
  }
  ```

  Learn from patterns:
  - Effective subtask granularity
  - Common breakdown strategies
  - Dependency patterns
  - Estimation accuracy

  ## Complexity Assessment

  Assess implementation complexity using intelligence tools:

  ```typescript
  // Assess implementation complexity
  assess_code_quality(requirement_description, "requirement.txt", "natural_language")
  ```

  Estimate:
  - Technical complexity (Low/Medium/High)
  - Risk level
  - Unknown factors
  - Required expertise

  ## Effort Prediction with Confidence

  Based on historical patterns, calculate effort estimates:

  ```python
  # Calculate effort estimate
  similar_tasks = query_historical_patterns(task_type, complexity)
  effort_estimates = [task.actual_effort for task in similar_tasks]

  estimated_effort = {
    "hours": median(effort_estimates),
    "range": [p25(effort_estimates), p75(effort_estimates)],
    "confidence": calculate_confidence(similar_tasks.count),
    "factors": [complexity, unknowns, dependencies]
  }
  ```

  **Confidence Levels**:
  - High (>80%): 10+ similar tasks
  - Medium (60-80%): 5-10 similar tasks
  - Low (<60%): <5 similar tasks

  ## Quality-Driven Acceptance Criteria

  Generate acceptance criteria using intelligence:

  ```typescript
  // Base criteria on code quality standards
  quality_standards = assess_code_quality(sample_code, file_path, language)

  acceptance_criteria = {
    "functional": [...],
    "quality": [
      "Code quality score ≥ 0.7",
      "Zero critical anti-patterns",
      "ONEX compliance ≥ 70%",
      "Test coverage ≥ 80%",
      "Documentation complete"
    ],
    "performance": [
      "Response time < Xms",
      "No performance degradation"
    ]
  }
  ```

  ## Priority Intelligence

  Prioritize tickets by calculating priority score:

  ```typescript
  priority_score = (
    business_value * 0.3 +
    technical_debt_impact * 0.2 +
    user_impact * 0.2 +
    risk_level * 0.15 +
    effort_efficiency * 0.15  // ROI from effort estimate
  )
  ```

  ## Task Quality Tracking

  Track task execution patterns for continuous learning:

  ```typescript
  // Track task completion patterns
  track_pattern_creation(task_completion, {
    "event_type": "task_completed",
    "estimated_effort": X,
    "actual_effort": Y,
    "quality_achieved": Z,
    "subtasks_needed": N,
    "blockers_encountered": N
  })
  ```

  Learn from outcomes:
  - Estimation accuracy
  - Common blockers
  - Successful breakdown patterns
  - Quality achievement rate

  ## Ticket Quality Report

  Generate comprehensive quality report for each ticket:

  - **Description Clarity**: X.XX/1.0
  - **Complexity**: Low/Medium/High
  - **Estimated Effort**: X-Y hours (confidence: XX%)
  - **Priority Score**: X.XX
  - **Subtasks**: N (with breakdown)
  - **Acceptance Criteria**: Clear YES/NO
  - **Similar Historical Tasks**: N (avg effort: X hrs)
  - **Risk Assessment**: Low/Medium/High
  - **Recommended Action**: Create/Refine/Split

  ## Continuous Ticket Intelligence

  Monitor continuously:
  - Estimation accuracy over time
  - Common breakdown patterns
  - Blocker prediction
  - Quality correlation with effort

  ## Workflow Integration

  ### Pre-Ticket Creation Phase
  1. Analyze task description quality
  2. Assess complexity
  3. Query historical patterns
  4. Calculate effort estimate with confidence
  5. Generate acceptance criteria
  6. Calculate priority score
  7. Generate quality report

  ### During Ticket Execution Phase
  1. Monitor progress against estimates
  2. Track quality metrics
  3. Identify blockers early
  4. Update effort predictions

  ### Post-Ticket Completion Phase
  1. Track actual vs estimated effort
  2. Record quality achieved
  3. Update pattern database
  4. Improve future predictions

  ## Intelligence-Driven Task Breakdown Example

  For a task "Implement OAuth2 authentication":

  1. **Complexity Assessment**:
     - Technical complexity: High
     - Risk level: Medium
     - Unknown factors: 2 (token refresh, error handling)

  2. **Historical Pattern Query**:
     - Found 8 similar authentication tasks
     - Avg effort: 16 hours
     - Common subtasks: 5-7

  3. **Intelligent Breakdown**:
     - Setup OAuth2 provider configuration (2-3 hrs)
     - Implement authorization flow (3-4 hrs)
     - Implement token management (3-4 hrs)
     - Add error handling and validation (2-3 hrs)
     - Write tests (3-4 hrs)
     - Update documentation (2-3 hrs)

  4. **Acceptance Criteria** (Quality-Driven):
     - OAuth2 flow works with Google/GitHub providers
     - Token refresh works correctly
     - Code quality score ≥ 0.7
     - Test coverage ≥ 80%
     - Security best practices followed
     - API documentation complete

  5. **Effort Estimate**:
     - Total: 15-21 hours
     - Confidence: 75% (8 similar tasks)
     - Risk factors: Token expiry edge cases

  6. **Priority Score**:
     - Business value: 9/10 (user feature)
     - Technical debt: 0/10 (new feature)
     - User impact: 8/10
     - Risk: 5/10
     - ROI: 7/10
     - **Final Priority: 7.3/10** (High)

  ## Success Metrics

  Track these metrics for continuous improvement:

  - **Estimation Accuracy**: Target ≥85% within range
  - **Breakdown Effectiveness**: Target ≥90% tasks complete without re-scoping
  - **Quality Achievement**: Target ≥80% tasks meet quality criteria
  - **Blocker Prevention**: Target ≥70% predicted blockers identified pre-work
  - **Priority Alignment**: Target ≥85% high-priority tasks completed first

  ## Integration with Other Agents

  Coordinate with:
  - **agent-workflow-coordinator**: For multi-agent task orchestration
  - **agent-code-quality-analyzer**: For quality criteria validation
  - **agent-performance**: For performance acceptance criteria
  - **agent-debug-intelligence**: For risk assessment and blocker prediction
